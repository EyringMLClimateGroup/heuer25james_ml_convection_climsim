{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6941e5c-270c-481b-bbfb-e319f3edf05b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 00:01:26.010783: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-11 00:01:28.119974: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-11 00:01:28.390063: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-11 00:01:28.900350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-11 00:01:29.102486: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-11 00:01:30.062139: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 00:01:47.925002: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from climsim_utils.data_utils import *\n",
    "from create_dataset_example_v5expandcnv_import import read_save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6276450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# npdata = np.load('/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandrad_postprocessed/train_input.npy')\n",
    "# # npdata2 = np.load('/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandrad_postprocessed/train_input.h5')\n",
    "# npdata.shape, npdata.shape[0]/21600\n",
    "\n",
    "# # import matplotlib.pyplot as plt\n",
    "# # plt.hist(npdata[:,59])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82db83-7ae0-423b-b994-7df5d734b101",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Instantiating class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b542b197-e371-4346-94b4-bc5ecfcf0f82",
   "metadata": {},
   "source": [
    "The example below will save training data in both .h5 and .npy format. Adjust if you only need one format. Also adjust input_abbrev to the input data files you will use. We expanded the original '.mli.' input files to include additional features such as previous steps' information, and '.mlexpand.' was just an arbitrary name we used for the expanded input files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aebd66-ae71-4db0-9c83-d6f5a56880a6",
   "metadata": {},
   "source": [
    "Currently the training script would assume the training set is in .h5 format while the validation set is in .npy form. It's fine to only keep save_h5=True in the block below for generating training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4baee2-c25e-4e14-bae4-038e67a40740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid_path = '/global/u2/z/zeyuanhu/nvidia_codes/Climsim_private/grid_info/ClimSim_low-res_grid-info.nc'\n",
    "# norm_path = '/global/u2/z/zeyuanhu/nvidia_codes/Climsim_private/preprocessing/normalizations/'\n",
    "\n",
    "grid_path = '/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/ClimSim_high-res_grid-info.nc'\n",
    "norm_path = '/p/project/icon-a-ml/heuer1/ClimSim/preprocessing/normalizations/'\n",
    "\n",
    "grid_info = xr.open_dataset(grid_path)\n",
    "input_mean = xr.open_dataset(norm_path + 'inputs/input_mean_v5_pervar.nc')\n",
    "input_max = xr.open_dataset(norm_path + 'inputs/input_max_v5_pervar.nc')\n",
    "input_min = xr.open_dataset(norm_path + 'inputs/input_min_v5_pervar.nc')\n",
    "output_scale = xr.open_dataset(norm_path + 'outputs/output_scale_std_lowerthred_v5.nc')\n",
    "\n",
    "data = data_utils(grid_info = grid_info, \n",
    "                  input_mean = input_mean, \n",
    "                  input_max = input_max, \n",
    "                  input_min = input_min, \n",
    "                  output_scale = output_scale,\n",
    "                  input_abbrev = 'mlexpandcnv',\n",
    "                  output_abbrev = 'mlo',\n",
    "                  #ml_backend = 'pytorch',\n",
    "                  normalize=False,\n",
    "                  save_h5=False,\n",
    "                  save_zarr=True,\n",
    "                  save_npy=False\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1cf9ea-41d1-4b72-bff1-9a900188e834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set data path\n",
    "# data.data_path = '/global/homes/z/zeyuanhu/scratch/hugging/E3SM-MMF_ne4/train/'\n",
    "data.data_path = '/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/train/'\n",
    "\n",
    "# set inputs and outputs to V5 subset\n",
    "data.set_to_v5cnvqcqi_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a7a139-d2f7-4229-8360-9f7f0422703e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['state_t',\n",
       "  'state_rh',\n",
       "  'state_q0002',\n",
       "  'state_q0003',\n",
       "  'liq_partition',\n",
       "  'state_u',\n",
       "  'state_v',\n",
       "  'state_t_prvphy',\n",
       "  'state_q0001_prvphy',\n",
       "  'state_q0002_prvphy',\n",
       "  'state_q0003_prvphy',\n",
       "  'state_u_prvphy',\n",
       "  'tm_state_t_prvphy',\n",
       "  'tm_state_q0001_prvphy',\n",
       "  'tm_state_q0002_prvphy',\n",
       "  'tm_state_q0003_prvphy',\n",
       "  'tm_state_u_prvphy',\n",
       "  'state_pmid',\n",
       "  'state_ps',\n",
       "  'pbuf_LHFLX',\n",
       "  'pbuf_SHFLX',\n",
       "  'pbuf_TAUX',\n",
       "  'pbuf_TAUY',\n",
       "  'pbuf_COSZRS',\n",
       "  'cam_in_ALDIF',\n",
       "  'cam_in_ALDIR',\n",
       "  'cam_in_ASDIF',\n",
       "  'cam_in_ASDIR',\n",
       "  'tm_state_ps',\n",
       "  'tm_pbuf_LHFLX',\n",
       "  'tm_pbuf_SHFLX',\n",
       "  'tm_pbuf_COSZRS',\n",
       "  'clat',\n",
       "  'slat'],\n",
       " ['ptend_t',\n",
       "  'ptend_q0001',\n",
       "  'ptend_q0002',\n",
       "  'ptend_q0003',\n",
       "  'ptend_u',\n",
       "  'ptend_v',\n",
       "  'cam_out_PRECSC',\n",
       "  'cam_out_PRECC'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.input_vars, data.target_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d01fa-eed6-493b-9e66-65b43796354b",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab985d2d-ce4b-4bfd-81cd-c67d9502a2fb",
   "metadata": {},
   "source": [
    "Below is an example of creating the training data by integrating the 7 year climsim simulation data. A subsampling of 1000 is used as an example. In the actual work we did, we used a stride_sample=1. We could not fit the full 7-year data into the memory wihout subsampling. If that's also the case for you, try to only process a subset of data at one time by adjusting regexps in set_regexps method. We saved 14 separate input .h5 files. For each year, we saved two files by setting start_idx=0 or 1. For each year, we saved two files by setting start_idx=0 or 1. We have a folder like v5_full, which includes 14 subfolders named '11', '12', '21', '22', ..., '71','72', and each subfolder contains a train_input.h5 and train_target.h5. How you split to save training data won't influence the training. The training script will read in all the samples and randomly select samples across all the samples to form each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f391ee4-8408-4aa4-944f-c71924718a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # default: ignore loop (one iteration)\n",
    "# split='train'\n",
    "# # regex_list = [f'E3SM-MMF.mlexpandcnv.0001-*-*.nc', 'E3SM-MMF.mlexpandcnv.0002-01-*-*.nc']\n",
    "# regex_list = [f'E3SM-MMF.mlexpandcnv.0001-{i:02d}-*.nc' for i in range(2, 13)] + ['E3SM-MMF.mlexpandcnv.0002-01-*-*.nc']\n",
    "# # split='val'\n",
    "# # regex_list = [f'E3SM-MMF.mlexpandcnv.0002-06-10-*.nc']\n",
    "# # split='test'\n",
    "# # regex_list = [f'E3SM-MMF.mlexpandcnv.0002-06-20-*.nc']\n",
    "\n",
    "# for i in tqdm(range(0,len(regex_list))):#-1,-1,-1)):#\n",
    "#         # set regular expressions for selecting training data\n",
    "#         # data.set_regexps(data_split = 'train',\n",
    "#         #                 regexps = [f'E3SM-MMF.mlexpandcnv.000[1234567]-*-*.nc',#{i:02d}-*.nc', # years 1 through 7\n",
    "#         #                         'E3SM-MMF.mlexpandcnv.0008-01-*-*.nc']) # first month of year 8\n",
    "#         data.set_regexps(data_split = split,\n",
    "#                          # regexps = regex_list)\n",
    "#                          regexps = [regex_list[i]])\n",
    "#         # set temporal subsampling\n",
    "#         data.set_stride_sample(data_split = split,stride_sample = 1)\n",
    "#         # create list of files to extract data from\n",
    "#         data.set_filelist(data_split = split, start_idx=0)\n",
    "#         # print(data.train_filelist)\n",
    "#         # print(len(sorted(data.val_filelist))\n",
    "#         # save numpy files of training data\n",
    "#         # print(f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnvcons_postprocessed/{i:02}')\n",
    "#         # save_path = f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnvcons_postprocessed/'\n",
    "#         # print(i)\n",
    "#         # save_path = f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi/'\n",
    "#         save_path = f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/{i:02}/'\n",
    "#         os.makedirs(save_path)#, exist_ok=True)\n",
    "#         data.save_as_npy(data_split = split, save_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e5bd36-dc3a-41d1-9931-22f409e62699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlexpandcnv_paths = glob.glob(f'{data.data_path}/**/E3SM-MMF.{data.input_abbrev}.*', recursive=True)\n",
    "yms = sorted(list(set([re.search(f'.*E3SM-MMF\\.{data.input_abbrev}\\.(\\d\\d\\d\\d-\\d\\d)-.*\\.nc', p).group(1) for p in mlexpandcnv_paths])))\n",
    "len(yms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f9246-681c-4a5f-a5df-6e3f15b9adc9",
   "metadata": {},
   "source": [
    "## mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6393e-9f4d-4ddd-9dd4-abf5bceb2da0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "mp.set_start_method('spawn')\n",
    "\n",
    "# test = []\n",
    "if __name__ == '__main__':\n",
    "    # Determine the number of processes based on system's capabilities or your preference\n",
    "    num_processes = mp.cpu_count()  # You can adjust this to a fixed number if preferred\n",
    "    print(num_processes)\n",
    "    num_processes = 24\n",
    "    args_for_processing = [(ym, 'train', '/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_qcqi') for ym in yms]\n",
    "    with mp.Pool(num_processes) as pool:\n",
    "        # Use pool.map to process files in parallel\n",
    "        pool.map(read_save_data, args_for_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "281ec08e-a53f-48f1-99a3-5f1bb5702839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0003-12']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exist_files = os.listdir('/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_qcqi')\n",
    "yms = [ym for ym in yms if ym not in exist_files]\n",
    "yms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a3aba40-1c24-4bfb-9961-d85361e20abb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data for 0003-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 00:02:54.500173: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-04-11 00:11:35.541528: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1/1 [09:28<00:00, 568.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing of /p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_qcqi/0003-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Determine the number of processes based on system's capabilities or your preference\n",
    "    args_for_processing = [(ym, 'train', '/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_qcqi') for ym in yms]\n",
    "    for arg in tqdm(args_for_processing[:]):\n",
    "        read_save_data(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942aa959-5dad-440d-b40c-05afd577ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Stop here in script mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4a4ff-b0c1-4497-b17b-554e790b2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_qcqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31f99d-d3ec-412d-a5f3-2061e1b36fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default: ignore loop (one iteration)\n",
    "split='train'\n",
    "# regex_list = [f'E3SM-MMF.mlexpandcnv.0001-*-*.nc', 'E3SM-MMF.mlexpandcnv.0002-01-*-*.nc']\n",
    "regex_list = [f'E3SM-MMF.mlexpandcnv.0001-{i:02d}-*.nc' for i in range(2, 13)] + ['E3SM-MMF.mlexpandcnv.0002-01-*-*.nc']\n",
    "# split='val'\n",
    "# regex_list = [f'E3SM-MMF.mlexpandcnv.0002-06-10-*.nc']\n",
    "# split='test'\n",
    "# regex_list = [f'E3SM-MMF.mlexpandcnv.0002-06-20-*.nc']\n",
    "\n",
    "for i in tqdm(range(0,len(regex_list))):#-1,-1,-1)):#\n",
    "        # set regular expressions for selecting training data\n",
    "        # data.set_regexps(data_split = 'train',\n",
    "        #                 regexps = [f'E3SM-MMF.mlexpandcnv.000[1234567]-*-*.nc',#{i:02d}-*.nc', # years 1 through 7\n",
    "        #                         'E3SM-MMF.mlexpandcnv.0008-01-*-*.nc']) # first month of year 8\n",
    "        data.set_regexps(data_split = split,\n",
    "                         # regexps = regex_list)\n",
    "                         regexps = [regex_list[i]])\n",
    "        # set temporal subsampling\n",
    "        data.set_stride_sample(data_split = split,stride_sample = 1)\n",
    "        # create list of files to extract data from\n",
    "        data.set_filelist(data_split = split, start_idx=0)\n",
    "        # print(data.train_filelist)\n",
    "        # print(len(sorted(data.val_filelist))\n",
    "        # save numpy files of training data\n",
    "        # print(f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnvcons_postprocessed/{i:02}')\n",
    "        # save_path = f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnvcons_postprocessed/'\n",
    "        # print(i)\n",
    "        # save_path = f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi/'\n",
    "        save_path = f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/{i:02}/'\n",
    "        os.makedirs(save_path)#, exist_ok=True)\n",
    "        data.save_as_npy(data_split = split, save_path = save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15656f06-ce32-4dae-b322-1f1d1b939b32",
   "metadata": {},
   "source": [
    "## end mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7404116-1076-406e-ba96-5f7083f69317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 176.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/00/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/01/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/02/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/03/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/04/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/05/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/06/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/07/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/08/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/09/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/10/train_input.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/11/train_input.zarr\n",
      "(36806400, 1096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 1621.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/00/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/01/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/02/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/03/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/04/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/05/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/06/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/07/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/08/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/09/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/10/train_target.zarr\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/11/train_target.zarr\n",
      "(36806400, 362)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For merging chunks\n",
    "from glob import glob\n",
    "import dask.array as da\n",
    "import h5py\n",
    "import shutil\n",
    "\n",
    "# in_tar = 'target'\n",
    "\n",
    "for in_tar in ['input', 'target']:\n",
    "    pathlist = sorted(glob(f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/**/train_{in_tar}.zarr', recursive=True))\n",
    "    print(len(pathlist))\n",
    "\n",
    "    datalist = []\n",
    "    for p in tqdm(pathlist):\n",
    "        print(p)\n",
    "        # datalist.append(np.load(p))\n",
    "        datalist.append(da.from_zarr(p))\n",
    "\n",
    "    # nparray = np.concatenate(datalist)\n",
    "    # print(nparray.shape)\n",
    "    daarray = da.concatenate(datalist)\n",
    "    print(daarray.shape)\n",
    "    daarray.rechunk().to_zarr(f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/train_{in_tar}.zarr')\n",
    "\n",
    "# np.save(f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed/train_input.npy', nparray)\n",
    "\n",
    "# # with h5py.File(f'/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed/train_target.h5', 'w') as hdf:\n",
    "# #     hdf.create_dataset('data', data=nparray, dtype=nparray.dtype)\n",
    "\n",
    "# del nparray, datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80dc02a-a3e2-4443-9381-061e90bc0894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 61.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/00\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/01\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/02\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/03\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/04\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/05\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/06\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/07\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/08\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/09\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/10\n",
      "/p/scratch/icon-a-ml/heuer1/LEAP/ClimSim_high-res/expandcnv_postprocessed_newqcqi_radfix/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(pathlist):\n",
    "    dirname = os.path.dirname(p)\n",
    "    print(dirname)\n",
    "    shutil.rmtree(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc28f9-f333-4433-b9cc-8d0ecc3d7f07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97cafa5c-0117-45e5-9488-0e2923f498f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set regular expressions for selecting validation data\n",
    "data.set_regexps(data_split = 'val',\n",
    "                 regexps = ['E3SM-MMF.mlexpand.0008-0[23456789]-*-*.nc', # months 2 through 9 of year 8\n",
    "                            'E3SM-MMF.mlexpand.0008-1[012]-*-*.nc', # months 10 through 12 of year 8\n",
    "                            'E3SM-MMF.mlexpand.0009-01-*-*.nc']) # first month of year 9\n",
    "# set temporal subsampling\n",
    "# data.set_stride_sample(data_split = 'val', stride_sample = 7)\n",
    "data.set_stride_sample(data_split = 'val', stride_sample = 700)\n",
    "# create list of files to extract data from\n",
    "data.set_filelist(data_split = 'val')\n",
    "# save numpy files of validation data\n",
    "data.save_as_npy(data_split = 'val', save_path = '/global/homes/z/zeyuanhu/scratch/hugging/E3SM-MMF_ne4/preprocessing/v5_example/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd7827-3210-444e-be21-9126518c3cc6",
   "metadata": {},
   "source": [
    "### Create test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14c81c8b-486b-4fab-8167-24e55b4c7719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.data_path = '/global/homes/z/zeyuanhu/scratch/hugging/E3SM-MMF_ne4/_test/'\n",
    "\n",
    "data.set_to_v5_vars()\n",
    "\n",
    "# set regular expressions for selecting validation data\n",
    "data.set_regexps(data_split = 'test',\n",
    "                 regexps = ['E3SM-MMF.mlexpand.0009-0[3456789]-*-*.nc', \n",
    "                            'E3SM-MMF.mlexpand.0009-1[012]-*-*.nc',\n",
    "                            'E3SM-MMF.mlexpand.0010-*-*-*.nc',\n",
    "                            'E3SM-MMF.mlexpand.0011-0[12]-*-*.nc'])\n",
    "# set temporal subsampling\n",
    "# data.set_stride_sample(data_split = 'test', stride_sample = 7)\n",
    "data.set_stride_sample(data_split = 'test', stride_sample = 700)\n",
    "# create list of files to extract data from\n",
    "data.set_filelist(data_split = 'test')\n",
    "# save numpy files of validation data\n",
    "data.save_as_npy(data_split = 'test', save_path = '/global/homes/z/zeyuanhu/scratch/hugging/E3SM-MMF_ne4/preprocessing/v5_example/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad0d01b8-b20c-4dec-a967-981f6ecf514b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input.h5\ttest_target.npy  train_target.h5   val_input.npy\n",
      "test_input.npy\ttrain_input.h5\t train_target.npy  val_target.h5\n",
      "test_target.h5\ttrain_input.npy  val_input.h5\t   val_target.npy\n"
     ]
    }
   ],
   "source": [
    "!ls /global/homes/z/zeyuanhu/scratch/hugging/E3SM-MMF_ne4/preprocessing/v5_example/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33e94e-3c7f-4714-8e36-64413ebd35c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (climlab)",
   "language": "python",
   "name": "heuer1_climlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
